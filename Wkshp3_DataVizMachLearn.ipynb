{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "Wkshp3_DataVizMachLearn.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJwyWNeyIS07",
        "colab_type": "text"
      },
      "source": [
        "## Matplotlib: an introduction"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCrdmxKeIS08",
        "colab_type": "text"
      },
      "source": [
        "matplotlib library is one of the most commonly used plotting libraries in Python, and its **pyplot** module operates similarly to MATLAB (https://matplotlib.org/users/pyplot_tutorial.html).\n",
        "\n",
        "Let's jump in!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fmk_brmzIS0-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 1\n",
        "# Importing libraries/modules we'll be using\n",
        "%matplotlib inline\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.cm as cm\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8MLWbcvaIS1E",
        "colab_type": "text"
      },
      "source": [
        "### Line and scatter plots"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AEYady-GIS1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 2\n",
        "# Line plot\n",
        "\n",
        "x = np.arange(0,101,10)    # creating an array from 0 to 100 in steps of 10\n",
        "y = np.square(x)           # creating an array by element-wise squaring of array \"x\"\n",
        "\n",
        "plt.plot(x, y)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Part of a Parabolic Plot')\n",
        "\n",
        "plt.savefig('parabolic.png')    # saving plot to the Figures folder (or overwrite if file already in folder)\n",
        "files.download(\"parabolic.png\") \n",
        "\n",
        "xmin, xmax = plt.xlim()    # get values for current x-axis limits\n",
        "print('xmin:', xmin, 'xmax:', xmax)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "auBXUENMIS1K",
        "colab_type": "text"
      },
      "source": [
        "*Note: If you run the above plot with an older distribution of Anaconda (with a pre-0.8 version of seaborn), you may find that plot gets rendered with a gray background/white gridlines; this is seaborn's default \"darkgrid\" style, and in earlier versions the style was automatically set upon import of the seaborn library (https://seaborn.pydata.org/tutorial/aesthetics.html). If this happens to you, move the seaborn import statement to the first coding cell under the Seaborn section of this notebook, clear all cell output (under the \"cell\" drop-down menu) and re-run the cells.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "-auWZofcIS1M",
        "colab_type": "text"
      },
      "source": [
        "What if we want to change the axes ranges?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zaRF1IZ4IS1N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 3\n",
        "# Line plot again, with adjusted axes\n",
        "\n",
        "x = np.arange(0,101,10)   \n",
        "y = np.square(x)           \n",
        "\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.xlim(0, 40)    # setting x-axis limits\n",
        "plt.ylim(0, 2000)  # setting y-axis limits\n",
        "\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Part of a Parabolic Plot - Zoomed In')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "07uXL1TbIS1R",
        "colab_type": "text"
      },
      "source": [
        "We can even flip an axis so that it shows values in decreasing order."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1NFgwHrBIS1T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 4\n",
        "# Line plot again, with flipped x-axis\n",
        "\n",
        "x = np.arange(0,101,10)   \n",
        "y = np.square(x)           \n",
        "\n",
        "plt.plot(x, y)\n",
        "\n",
        "plt.xlim(105, -5)    # setting x-axis limits\n",
        "\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Part of a Parabolic Plot - Flipped')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hFdl2bpiIS1X",
        "colab_type": "text"
      },
      "source": [
        "Alright, let's say that we're happy with these x- and y- limits. What if we want to change the color and style of the plotted line?\n",
        "\n",
        "`plt.plot()` allows you to specify formatting options for each x-y dataset you're plotting. Each formatting type is optional (not specifying just means default values will be used), but must be specified in a string in the following order: *color* + *marker style* + *line style*. See the following example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVXz9Lq9IS1Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 5\n",
        "# Line plot again, this time with customized formatting\n",
        "\n",
        "x = np.arange(0,101,10)   \n",
        "y = np.square(x)           \n",
        "\n",
        "plt.plot(x, y, 'mo--')    # color = magenta, marker = circle, line style = dashed\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.title('Part of a Parabolic Plot - Magenta')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qtFtzcLgIS1c",
        "colab_type": "text"
      },
      "source": [
        "For all available color/marker/line style options, take a look at the \"Notes\" section in the `plt.plot()` documentation: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.plot.html#matplotlib.pyplot.plot. You can also specify properties such as linewidth and markersize after the string formatter; check out the **kwargs properties listed at the same link."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "836MftnZIS1e",
        "colab_type": "text"
      },
      "source": [
        "`plt.plot()` can be used to create simple scatter plots as well - and if you don't need your data points to vary in marker size/color, the documentation recommends that you stick with `plot()`. However, there is a separate `plt.scatter()` function which does allow you to change how you display different data points."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SpzDamDNIS1f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 6\n",
        "# An example using plt.scatter()\n",
        "\n",
        "x = np.linspace(0,1,100)\n",
        "np.random.seed(7)        # by specifying a seed #, we ensure the random #s generated below are the same each time the cell is run\n",
        "y = np.random.randn(100)       # creating an array of 100 random normally-distributed numbers\n",
        "outer = np.empty(100)    # initializing a 100 x 1 array; specific elements are assigned below\n",
        "outer[np.abs(y) < 1.5] = 10    # set element = 10 if the absolute value of the corresponding element in y is < 1.5\n",
        "outer[np.abs(y) >= 1.5] = 30   # set element = 30 if the absolute value of the corresponding element in y is >=1.5\n",
        "\n",
        "# \"s\" corresponds to marker size, \"c\" to marker color, \"cmap\" to the colormap used to plot, and \"alpha\" to transparency\n",
        "plt.scatter(x, y, s=outer, c=outer, cmap = cm.coolwarm, alpha = 0.75)\n",
        "\n",
        "plt.title('Scatter Plot')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "owemTQsjIS1j",
        "colab_type": "text"
      },
      "source": [
        "The documentation for `plt.scatter()` can be found here: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.scatter.html. Also, to look at the colormaps available, follow this link: https://matplotlib.org/examples/color/colormaps_reference.html"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xlS6M-kZIS1p",
        "colab_type": "text"
      },
      "source": [
        "### Multiple plotting, subplots, and insets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MBRVrSENIS1q",
        "colab_type": "text"
      },
      "source": [
        "What if you want to plot multiple data series? If you're calling `plt.plot()` on both of them, you can just add the x, y, and formatting options in the same call:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZwbtARkIS1s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 7\n",
        "# Two series plotted as lines\n",
        "\n",
        "x = np.arange(0,101,10)   \n",
        "y1 = np.square(x)\n",
        "y2 = np.power(x, 2.2)\n",
        "\n",
        "plt.plot(x, y1, 'mo--', x, y2, 'gD-')    # color = magenta, marker = circle, line style = dashed\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend(['Series 1','Series 2'])\n",
        "plt.title('Plotting Two Series')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_1eFxppIS1z",
        "colab_type": "text"
      },
      "source": [
        "Alternative, you can just add function calls in sequence. You can repeat a call to the same function, or call a new plotting function, like so:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ho3niGtSIS10",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 8\n",
        "# Line plot and scatter plot\n",
        "\n",
        "x1 = np.arange(0,101,10)\n",
        "x2 = np.arange(10,91,5)\n",
        "y1 = np.square(x1)  \n",
        "y2 = np.power(x2, 2.2)\n",
        "\n",
        "plt.plot(x1, y1, 'mo--')\n",
        "plt.scatter(x2, y2)\n",
        "\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend(['Line','Scatter'])\n",
        "plt.title('Part of a Parabolic Plot - Magenta')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LGPtJzBJIS15",
        "colab_type": "text"
      },
      "source": [
        "To create multiple subplots in a single figure, we can use `plt.subplot(nrows, ncols, index)` where *nrows* and *ncols* specifies the number of rows and columns of subplots you want to create, and *index* refers to the position of the exact subplot you are currently developing. The commas between each argument (*nrows*, etc.) are optional."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RrfBU6LWIS16",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 9\n",
        "# A figure with four subplots\n",
        "\n",
        "x1 = np.arange(0.01, 10, 0.1)    # x is the range of numbers from 0.01 to 10 with stepsize = 0.1\n",
        "y1 = np.log(x1)\n",
        "y2 = x1\n",
        "y3 = np.square(x1)\n",
        "y4 = np.power(2, x1)\n",
        "\n",
        "plt.figure(figsize=(5,5), dpi=100)    # instantiating figure to be 5\"x5\", 100 dpi resolution\n",
        "\n",
        "# Top-left\n",
        "plt.subplot(2,2,1)\n",
        "plt.plot(x1, y1)\n",
        "plt.title('log')\n",
        "\n",
        "# Top-right\n",
        "plt.subplot(2,2,2)\n",
        "plt.plot(x1, y2)\n",
        "plt.title('linear')\n",
        "\n",
        "# Bottom-left\n",
        "plt.subplot(2,2,3)\n",
        "plt.plot(x1, y3)\n",
        "plt.title('quadratic')\n",
        "\n",
        "# Bottom-right\n",
        "plt.subplot(2,2,4)\n",
        "plt.plot(x1,y4)\n",
        "plt.title(r'$2^x$')    # formatting text with mathematical expressions: use TeX formatting\n",
        "\n",
        "# Setting width of whitespace between subplots to be 0.3 x average axis width, height to be 0.3 x average axis height \n",
        "plt.subplots_adjust(wspace=0.3, hspace=0.3)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELg9odOLIS19",
        "colab_type": "text"
      },
      "source": [
        "For more flexibility in subplot layout, we can use `plt.GridSpec()`. GridSpec allows you to refer to positions of subplots using standard Python zero-based indexing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LNCbv7A8IS1_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 10\n",
        "# Example using GridSpec\n",
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "x1 = np.arange(0.01, 10, 0.1)\n",
        "y1 = x1\n",
        "y2 = np.square(x1)\n",
        "y3 = np.sin(x1)\n",
        "y4 = np.power(2, x1)\n",
        "y5 = np.power(3, x1)\n",
        "\n",
        "# Creating a 10\" x 5\" figure with silver background\n",
        "plt.figure(figsize=(10, 5), facecolor='silver')\n",
        "\n",
        "# Creating a 3 x 2 layout of subplots; width_ratios and height_ratios correspond to the relative aspect ratios of each dimension\n",
        "grid = gridspec.GridSpec(3, 2, wspace=0.2, hspace=0.7, width_ratios = [1, 1], height_ratios = [1, 1, 2])\n",
        "\n",
        "# Top-left\n",
        "plt.subplot(grid[0, 0])\n",
        "plt.plot(x1, y1)\n",
        "plt.title('linear', fontsize=20)\n",
        "\n",
        "# Top-right\n",
        "plt.subplot(grid[0, 1])\n",
        "plt.plot(x1, y2)\n",
        "plt.title('quadratic', fontsize=20)\n",
        "\n",
        "# Middle\n",
        "plt.subplot(grid[1, :])\n",
        "plt.plot(x1, y3)\n",
        "plt.title('sin(x)', fontsize=20)\n",
        "plt.grid()\n",
        "\n",
        "# Bottom-left\n",
        "plt.subplot(grid[2, 0])\n",
        "plt.plot(x1, y4)\n",
        "plt.title(r'$2^x$', fontsize = 20)\n",
        "\n",
        "# Bottom-right\n",
        "plt.subplot(grid[2, 1])\n",
        "plt.plot(x1, y5)\n",
        "plt.title(r'$3^x$', fontsize = 20)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dcRXkylgIS2C",
        "colab_type": "text"
      },
      "source": [
        "For inset plots, "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wlnbc1fQIS2D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 11\n",
        "\n",
        "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes, mark_inset\n",
        "\n",
        "# Function that generates a random walk with N=500\n",
        "def randomwalk(seed_num):\n",
        "    init_pos = 0\n",
        "    t = []\n",
        "    y = []\n",
        "    np.random.seed(seed_num)    # seeding random generator with specified number so the same figure appears when cell re-executed\n",
        "    rn = np.random.randn(500)\n",
        "    step = 0\n",
        "    for k in range(500):\n",
        "        t.append(k)\n",
        "        if rn[k] > 0:\n",
        "            step = +1\n",
        "        else:\n",
        "            step = -1\n",
        "        init_pos += step\n",
        "        y.append(init_pos)\n",
        "    return np.array(t), np.array(y)\n",
        "\n",
        "# Creating first random walk\n",
        "t1, y1 = randomwalk(4)\n",
        "\n",
        "# Creating second random walk\n",
        "t2, y2 = randomwalk(7)\n",
        "\n",
        "# Plot\n",
        "fig, ax = plt.subplots(figsize = [12,10])              # creating 12\" x 10\" figure and an axes object (the bounded plot) inside \n",
        "ax.plot(t1, y1, t2, y2)                                # plotting in main axes\n",
        "ax.set_xlabel('t', size=15, weight='bold')             # works like plt.xlabel() but can be individualized for each axes object\n",
        "ax.set_ylabel('y', size=15, weight='bold')\n",
        "ax.set_title('Random Walk, N=500', size=15, weight='bold')\n",
        "ax_inset = zoomed_inset_axes(ax, zoom=3, loc=7)        # \"zoom\" sets scaling factor, \"loc\" sets location of inset\n",
        "ax_inset.plot(t1, y1, t2, y2)                          # plotting in inset axes\n",
        "ax_inset.set_xlim(0, 20)                               # setting lower and upper x-bounds for the inset\n",
        "ax_inset.set_ylim(-2.2, 4.2)                           # setting lower and upper y-bounds for the inset\n",
        "mark_inset(ax, ax_inset, loc1=2, loc2=3, ec='0.75')    # connecting main plot and inset plot via left corners using gray edgecolor\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIsfJu9wIS2G",
        "colab_type": "text"
      },
      "source": [
        "For more on the parameters that can be adjusted with `zoomed_inset_axes()`, check out the documentation at https://matplotlib.org/2.0.2/mpl_toolkits/axes_grid/api/inset_locator_api.html#mpl_toolkits.axes_grid1.inset_locator.zoomed_inset_axes.\n",
        "\n",
        "For more on the parameters that can be adjusted with `mark_inset()`, check out the documentation at : https://matplotlib.org/2.0.2/mpl_toolkits/axes_grid/api/inset_locator_api.html#mpl_toolkits.axes_grid1.inset_locator.mark_inset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PI8DjNu_IS2H",
        "colab_type": "text"
      },
      "source": [
        "### Bar plots and error bars"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jp4iyNOLIS2I",
        "colab_type": "text"
      },
      "source": [
        "The main function for bar plots is `plt.bar()`. Let's look at a bar plot with two data series (effects of cell treatments at t1 vs t2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmT3ZQZZIS2J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 12\n",
        "# Cell treatment experiment\n",
        "\n",
        "treatments = ['Control', 'T32G5', 'T32G7']\n",
        "effect_t1 = [39.03, 30.36, 31.37]\n",
        "effect_t2 = [36.06, 35.87, 67.88]\n",
        "\n",
        "x_pos = np.array([1, 3, 5])             # setting array which will control the spacing of bars between each treatment\n",
        "barwidth = 0.6\n",
        "plt.bar(x_pos, effect_t1, width=barwidth, color='b', alpha=0.5, hatch='/')    # plotting t1 series\n",
        "plt.bar(x_pos + barwidth, effect_t2, width=barwidth, color='m', alpha=0.8, hatch='\\\\')    # plotting t2 series\n",
        "plt.xticks(x_pos + 0.5*barwidth, treatments, rotation=45)    # setting position, labels, rotation (degrees) of x-tick labels\n",
        "plt.xlim(0, 6.6)\n",
        "plt.ylim(0, 80)\n",
        "plt.ylabel('Effect (%)', size=12)\n",
        "plt.legend(['t = 1h', 't = 2h'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nz8Rlz3PIS2N",
        "colab_type": "text"
      },
      "source": [
        "As you may have noticed, using `matplotlib.plt` allows us to customize the plot to a fine level of detail (there are a lot more formatting details that could be changed but weren't for the sake of brevity). However, sometimes we'd prefer the module to automatically arrange optimal settings (for example, we might not want to have to specify the spacing between multiple data series). That's where the seaborn package is preferable. We won't go through making bar plots in seaborn in this workshop, but if you're interested, see the documentation for `seaborn.barplot()`: https://seaborn.pydata.org/generated/seaborn.barplot.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GpkEhHcmIS2O",
        "colab_type": "text"
      },
      "source": [
        "We can add error bars to the above plot by specifying additional parameters when `plt.bar()` is called."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM8BuxrmIS2P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 13\n",
        "# Cell treatment experiment with error bars\n",
        "\n",
        "treatments = ['Control', 'T32G5', 'T32G7']\n",
        "effect_t1 = [39.03, 30.36, 31.37]\n",
        "effect_t2 = [36.06, 35.87, 67.88]\n",
        "sd_t1 = [11.99, 5.39, 6.51]\n",
        "sd_t2 = [8.23, 10.16, 8.46]\n",
        "\n",
        "x_pos = np.array([1, 3, 5])             \n",
        "barwidth = 0.6\n",
        "\n",
        "# Below, \"yerr\" defines the vertical error (+/-), capsize defines the length of the error bar caps \n",
        "plt.bar(x_pos, effect_t1, width=barwidth, yerr=sd_t1, capsize = 3, color='b', alpha=0.5, hatch='/')   \n",
        "plt.bar(x_pos + barwidth, effect_t2, width=barwidth, yerr=sd_t2, capsize = 3, color='m', alpha=0.8, hatch='\\\\')   \n",
        "\n",
        "plt.xticks(x_pos + 0.5*barwidth, treatments, rotation=45)  \n",
        "plt.xlim(0, 6.6)\n",
        "plt.ylim(0, 80)\n",
        "plt.ylabel('Effect (%)', size=12)\n",
        "plt.legend(['t = 1h', 't = 2h'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0EEV5ktIS2S",
        "colab_type": "text"
      },
      "source": [
        "More generally, error bars can be created with line/scatter plots using `plt.errorbar`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvCXBWxhIS2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 14\n",
        "# Example using plt.errorbar()\n",
        "\n",
        "time = np.arange(12)\n",
        "shift = [10, 11, 14, 22, 26, 31, 38, 39, 41, 41, 42, 42]\n",
        "std = [2, 2, 4, 6, 5, 6, 8, 8, 10, 11, 11, 10]\n",
        "\n",
        "# Below, \"fmt\" allows formatting of the line and markers, \"ecolor\" = error bar color, \"elinewidth\" = error bar linewidth\n",
        "plt.errorbar(time, shift, yerr=std, fmt='o-', ecolor='0.2', elinewidth=1, capsize=3)\n",
        "plt.xlabel('Time (s)')\n",
        "plt.ylabel('Shift (nm)')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKS6SxBLIS2b",
        "colab_type": "text"
      },
      "source": [
        "For more on the parameters that can be adjusted with `plt.errorbar()`, check out the documentation at https://matplotlib.org/api/_as_gen/matplotlib.pyplot.errorbar.html."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ViEjZkZaIS2c",
        "colab_type": "text"
      },
      "source": [
        "### Box plots and histograms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bQ6vhKyOIS2d",
        "colab_type": "text"
      },
      "source": [
        "Often, we'll be interested in the distribution of some dataset. Matplotlib's `plt.boxplot()` allows you to quickly construct a box-and-whiskers plot (a.k.a. box plot)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "pqOB1EH1IS2f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 15\n",
        "# Pulling in 1990-2010 U.S. census data, retrieved from https://en.wikipedia.org/wiki/List_of_U.S._states_by_historical_population\n",
        "files.upload()\n",
        "# Extracting lists of population counts in each of the 50 U.S. states in 1990, 2000, and 2010\n",
        "df = pd.read_csv('UScensusdata_50states.txt', sep='\\t', header=1)\n",
        "pops_90 = df['1990'].str.replace(',', '').astype('int64').values.tolist()\n",
        "pops_00 = df['2000'].str.replace(',', '').astype('int64').values.tolist()\n",
        "pops_10 = df['2010'].str.replace(',', '').astype('int64').values.tolist()\n",
        "\n",
        "# Creating boxplot with '1990', '2000', '2010' populations; setting patch_artist to True allows customization of plot style\n",
        "bp = plt.boxplot([pops_90, pops_00, pops_10], patch_artist=True, labels=['1990', '2000', '2010'])\n",
        "\n",
        "# boxplot() returns keys that can be set to different values; one such key is 'boxes' which corresponds to the main box body\n",
        "for i in bp['boxes']:\n",
        "    i.set_facecolor((0.1, 0.2, 0.5))\n",
        "\n",
        "plt.xlabel('Year', size=12)\n",
        "plt.ylabel('Population (10s of millions)', size=12)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJgPBKc_IS2i",
        "colab_type": "text"
      },
      "source": [
        "As a disclaimer, pandas data frames do have their own boxplot method. Here, I wanted to show the generalized way to create boxplots using matplotlib (upon which `pd.DataFrame.boxplot()` is built)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dWxsz-pPIS2j",
        "colab_type": "text"
      },
      "source": [
        "Histograms can be created using `plt.hist()`:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3xjH5YuDIS2k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 16\n",
        "# Example distribution using sample data from normal distribution\n",
        "\n",
        "np.random.seed(10)\n",
        "distr = 10 + np.random.randn(1000)*5\n",
        "\n",
        "# Creating a histogram from the distribution with 20 bins, counts normalized to get probability density\n",
        "histogram = plt.hist(distr, bins=20, density=True, alpha=0.7)\n",
        "n, bins, patches = histogram        # plt.hist() returns values for bin values, bin edges, and patches used to make histogram\n",
        "plt.xlabel('x', size=12)\n",
        "plt.ylabel('Probability', size=12)\n",
        "plt.show()\n",
        "\n",
        "print('Values for each bin:', n)\n",
        "print('Edges of the bins:', bins)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdVWY-y4IS2n",
        "colab_type": "text"
      },
      "source": [
        "### Logarithmic scaling and text annotation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPP2ir5cIS2o",
        "colab_type": "text"
      },
      "source": [
        "For non-linear axes, change the \"scale\" parameter of `plt.xscale()` and/or `plt.yscale()` as needed."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ahzSBb_ZIS2p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 17\n",
        "# Plotting background scattering data\n",
        "files.upload()\n",
        "# Reading in data \n",
        "q = []\n",
        "i = []\n",
        "with open('saxs_scatter.txt', 'r') as scatter:\n",
        "    next(scatter)\n",
        "    for line in scatter:\n",
        "        line = line.split()\n",
        "        x, y = float(line[0]), float(line[1])\n",
        "        q.append(x)\n",
        "        i.append(y)\n",
        "\n",
        "# Plotting\n",
        "plt.plot(q, i, 'D', markersize=2)\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.xlabel(r'q $[\\AA]^{-1}$', size=12)\n",
        "plt.xlim(0.002, 0.15)\n",
        "plt.xticks(fontsize=12)\n",
        "\n",
        "plt.yscale('log')\n",
        "plt.ylabel(r'I $[cm]^{-1}$', size=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "plt.title('Background Scattering')\n",
        "plt.grid(alpha=0.5)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A6GmIX-LIS2s",
        "colab_type": "text"
      },
      "source": [
        "There are also options for logit and symlog (like log, but handles negative data) scaling. See the documentation for details: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.xscale.html. You can also change the way the ticks are formatted using `matplotlib.ticker`: https://matplotlib.org/api/ticker_api.html#module-matplotlib.ticker."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJgwZNxZIS2t",
        "colab_type": "text"
      },
      "source": [
        "What if we wanted to add text inside the plot? Matplotlib's `plt.text()` and `plt.annotate()` allows you to do just that."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9INvGiAdIS2u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 18\n",
        "# Re-plotting the previous plot with text added\n",
        "\n",
        "plt.plot(q, i, 'D', markersize=2)\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.xlabel(r'q $[\\AA]^{-1}$', size=12)\n",
        "plt.xlim(0.002, 0.15)\n",
        "plt.xticks(fontsize=12)\n",
        "\n",
        "plt.yscale('log')\n",
        "plt.ylabel(r'I $[cm]^{-1}$', size=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "plt.title('Background Scattering')\n",
        "plt.grid(alpha=0.5)\n",
        "\n",
        "# Adding text centered at q=0.07, I=0.16\n",
        "plt.text(x=0.07, y=0.16, s=\"sample peak\\nshould appear here\", horizontalalignment='center', weight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KnRVRuW4IS2x",
        "colab_type": "text"
      },
      "source": [
        "To draw a pointer from the text to a specific point in the plot, use `plt.annotate()` and adjust the \"arrowprops\" parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib6x9ibqIS2x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 19\n",
        "# Re-plotting the previous plot with annotation/arrow\n",
        "\n",
        "plt.plot(q, i, 'D', markersize=2)\n",
        "\n",
        "plt.xscale('log')\n",
        "plt.xlabel(r'q $[\\AA]^{-1}$', size=12)\n",
        "plt.xlim(0.002, 0.15)\n",
        "plt.xticks(fontsize=12)\n",
        "\n",
        "plt.yscale('log')\n",
        "plt.ylabel(r'I $[cm]^{-1}$', size=12)\n",
        "plt.yticks(fontsize=12)\n",
        "\n",
        "plt.title('Background Scattering')\n",
        "plt.grid(alpha=0.5)\n",
        "\n",
        "# Adding annotation; \"xy\" = coordinates of point to annotate, xytext = location of text\n",
        "plt.annotate(s=\"sample peak\\nshould appear here\", xy=(0.08, 0.09), xytext=(0.06, 0.20), arrowprops=dict(arrowstyle=\"->\"), \n",
        "             horizontalalignment='center', weight='bold')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8_Z8sUPtIS23",
        "colab_type": "text"
      },
      "source": [
        "There are a lot of options you can specify. Check out the documentation for `plt.annotate()` here: https://matplotlib.org/api/_as_gen/matplotlib.pyplot.annotate.html?highlight=annotate#matplotlib-pyplot-annotate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2XxE7hCdIS25",
        "colab_type": "text"
      },
      "source": [
        "*The matplotlib gallery has an extensive collection of example visualizations along with corresponding code. We've only touched the surface today. You can find the gallery here: https://matplotlib.org/gallery.html.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YA8Ygn2oIS27",
        "colab_type": "text"
      },
      "source": [
        "## Seaborn: a sneak peek"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PDyUBkrDIS28",
        "colab_type": "text"
      },
      "source": [
        "Seaborn is another library built on matplotlib which allows users to create more \"attractive and informative statistical graphics\" (https://seaborn.pydata.org/introduction.html)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gdSJr9F0IS3A",
        "colab_type": "text"
      },
      "source": [
        "The first thing we'll do is to set the default plotting style. This can be done using the blanket `sns.set()` method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAv-1c9pIS3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 20\n",
        "\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HB3uqSVNIS3E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 21\n",
        "# Re-plotting one of our earlier plots\n",
        "\n",
        "x = np.arange(0,101,10)   \n",
        "y1 = np.square(x)\n",
        "y2 = np.power(x, 2.2)\n",
        "\n",
        "plt.plot(x, y1, x, y2)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend(['Series 1','Series 2'])\n",
        "plt.title('Plotting Two Series')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_3mBIO5IS3I",
        "colab_type": "text"
      },
      "source": [
        "Using sns.set() sets the default style/theme (\"darkgrid\"), color palette, and context (\"notebook\"). There are several options for each, which can be adjusted using `sns.set_style()`, `sns.set_palette()`, `sns.set_context()`, respectively. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3D_8RGgIS3I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 22\n",
        "# Let's set the context as example\n",
        "\n",
        "# Options: \"notebook\" (default), \"paper\", \"talk\", \"poster\"\n",
        "sns.set_context(\"talk\")\n",
        "\n",
        "# Re-plot \"Plotting Two Series\"\n",
        "plt.plot(x, y1, x, y2)\n",
        "plt.xlabel('x')\n",
        "plt.ylabel('y')\n",
        "plt.legend(['Series 1','Series 2'])\n",
        "plt.title('Plotting Two Series')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7t5F9HnWIS3b",
        "colab_type": "text"
      },
      "source": [
        "Using `sns.set_style()`, `sns.set_palette()`, and `sns.set_context()`, will set the respective attribute for all plots going forward. If you want to specify the style, palette, or context for an individual plot, use `sns.axes_style()`, `sns.color_palette()`, or `sns.plotting_context()`. To learn more, check out these tutorial pages: https://seaborn.pydata.org/tutorial/aesthetics.html (style and context), https://seaborn.pydata.org/tutorial/color_palettes.html (palette)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eqnK_6NdIS3c",
        "colab_type": "text"
      },
      "source": [
        "### Example plots in seaborn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQc7F2gYIS3d",
        "colab_type": "text"
      },
      "source": [
        "Let's look at some plots that seaborn makes easy. The first is `sns.pairplot()`, which plots pairwise relationships between attributes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D-G7hhnlIS3f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 23\n",
        "# Loading Boston dataset from scikit-learn; there are 13 housing-related attributes (not including the class, median value) \n",
        "# and 506 instances. For details about the dataset: http://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html\n",
        "\n",
        "from sklearn.datasets import load_boston\n",
        "boston = load_boston()\n",
        "dfB = pd.DataFrame(boston.data[:, 5:10], columns=boston.feature_names[5:10])    # data needs to be in data frame format\n",
        "print('We truncated the data to five columns for easier visualization:\\n')\n",
        "print(dfB.head())\n",
        "\n",
        "# Pairplot; the keyword argument \"s\" refers to the marker size\n",
        "sns.pairplot(dfB, plot_kws={'s': 7})\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Y-n_VdOIS3i",
        "colab_type": "text"
      },
      "source": [
        "It looks like there could be a linear relationship between AGE and DIS. For a simple linear regression fit and plot, we can use `sns.regplot()`. By default, the 95% confidence interval will also be plotted."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03tGJHr8IS3j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 24\n",
        "# AGE vs. DIS in Boston dataset\n",
        "\n",
        "age = dfB['AGE']\n",
        "dist = dfB['DIS']\n",
        "\n",
        "# Plotting regression, with figure-specific style change to white/grid-less background\n",
        "sns.regplot(x=age, y=dist, scatter_kws={'s':10})\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rSIfMAAfIS3m",
        "colab_type": "text"
      },
      "source": [
        "We saw a histogram earlier using just matplotlib. Seaborn has a method called `sns.distplot()` which allows us to simultaneously plot a histogram and a kernel density estimation (KDE)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MKhI5kT5IS3n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 25\n",
        "# Our distribution with sns.distplot()\n",
        "\n",
        "np.random.seed(10)\n",
        "distr = 10 + np.random.randn(1000)*5\n",
        "\n",
        "# Creating a histogram and KDE from the distribution with 20 bins\n",
        "sns.distplot(distr, bins=20)\n",
        "plt.xlabel('x', size=12)\n",
        "plt.ylabel('Probability', size=12)\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_Aab5_8IS3q",
        "colab_type": "text"
      },
      "source": [
        "Lastly, let's look at a seaborn favorite: the violin plot. It's essentially a KDE plotted over a box plot."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ftzL81-IS3r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 26\n",
        "# Using our U.S. Census data again\n",
        "\n",
        "with sns.color_palette('Set2'):\n",
        "    vp = sns.violinplot(data=[pops_90, pops_00, pops_10])\n",
        "vp.set_xticklabels(['1990','2000','2010'])\n",
        "plt.xlabel('Year')\n",
        "plt.ylabel('Population (10s of millions)')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9OiP3EgBntdT",
        "colab_type": "text"
      },
      "source": [
        "*For more examples using seaborn, check out the gallery here: https://seaborn.pydata.org/examples/index.html.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1-U8brO5nJMe",
        "colab_type": "text"
      },
      "source": [
        "## Machine learning with scikit-learn\n",
        "*The following materials (including text, code, and figures) were adapted from the \"SciPy 2017 Scikit-learn Tutorial\" by Alexandre Gramfort and Andreas Mueller. The contents of their tutorial are licensed under Creative Commons CC0 1.0 Universal License as work dedicated to the public domain, and can be found at https://github.com/amueller/scipy-2017-sklearn.*\n",
        "\n",
        "## What is Machine Learning?\n",
        "\n",
        "Machine learning is the process of extracting knowledge from data automatically, usually with the goal of making predictions on new, unseen data. Put another way, you are giving samples of data to the machine, which tries to infer observations from the data.\n",
        "\n",
        "Two key concepts:\n",
        "- **automating decision making** from data **without the user specifying explicit rules** for how this decision should be made\n",
        "- **generalization**: the goal of a machine learning model is to predict on new, previously unseen data\n",
        "\n",
        "The data is usually presented to the algorithm as a two-dimensional array (or matrix) of numbers. Each data point (also known as a *sample* or *training instance*) is represented as a list of numbers, a so-called feature vector, and the features that comprise the vector represent the properties of this point. \n",
        "\n",
        "For instance, we can represent a dataset consisting of 150 samples and 4 features as a 2-dimensional array or matrix $\\mathbb{R}^{150 \\times 4}$ in the following format:\n",
        "\n",
        "\n",
        "$$\\mathbf{X} = \\begin{bmatrix}\n",
        "    x_{1}^{(1)} & x_{2}^{(1)} & x_{3}^{(1)} & \\dots  & x_{4}^{(1)} \\\\\n",
        "    x_{1}^{(2)} & x_{2}^{(2)} & x_{3}^{(2)} & \\dots  & x_{4}^{(2)} \\\\\n",
        "    \\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\n",
        "    x_{1}^{(150)} & x_{2}^{(150)} & x_{3}^{(150)} & \\dots  & x_{4}^{(150)}\n",
        "\\end{bmatrix}.\n",
        "$$\n",
        "\n",
        "(The superscript denotes the *i*th row, and the subscript denotes the *j*th feature, respectively."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7aMLL0YdIS3t",
        "colab_type": "text"
      },
      "source": [
        "Data in scikit-learn, with very few exceptions, is assumed to be stored as a\n",
        "**two-dimensional array**, of shape `[n_samples, n_features]`.\n",
        "\n",
        "- **n_samples:**   The number of samples: each sample is an item to process (e.g. classify).\n",
        "  A sample can be a document, a picture, a sound, a video, an astronomical object,\n",
        "  a row in database or CSV file,\n",
        "  or whatever you can describe with a fixed set of quantitative traits.\n",
        "- **n_features:**  The number of features or distinct traits that can be used to describe each\n",
        "  item in a quantitative manner.  Features are generally real-valued, but may be Boolean or\n",
        "  discrete-valued in some cases.\n",
        "\n",
        "The number of features must be fixed in advance. However it can be very high dimensional\n",
        "(e.g. millions of features) with most of them being \"zeros\" for a given sample. This is a case\n",
        "where `scipy.sparse` matrices can be useful, in that they are\n",
        "much more memory-efficient than NumPy arrays.\n",
        "\n",
        "\n",
        "There are two kinds of machine learning we will talk about today: ***supervised learning*** and ***unsupervised learning***.\n",
        "\n",
        "### Supervised Learning: Classification and regression\n",
        "\n",
        "In **Supervised Learning**, we have a dataset consisting of both input features (observed quantities) and a desired output (what we want to determine).\n",
        "\n",
        "Some examples are:\n",
        "\n",
        "- Given a photograph of a person, identify the person in the photo.\n",
        "- Given a list of movies a person has watched and their personal ratings\n",
        "  of the movies, recommend a list of movies they would like.\n",
        "- Given a persons age, education and position, infer their salary.\n",
        "\n",
        "Supervised learning is further broken down into two categories, **classification** and **regression**:\n",
        "\n",
        "- **In classification, the label is discrete**, such as \"spam\" or \"no spam\" for an email. \n",
        "\n",
        "- **In regression, the label is continuous** (a float output). \n",
        "\n",
        "In supervised learning, there is always a distinction between a **training set** for which the desired outcome (a certain label or class) is given, and a **test set** for which the desired outcome needs to be inferred. The learning model fits the predictive model to the training set, and we use the test set to evaluate its generalization performance.\n",
        "\n",
        "### Unsupervised Learning\n",
        "\n",
        "In **Unsupervised Learning** there is no desired output associated with the data.\n",
        "Instead, we are interested in extracting some form of knowledge or model from the given data.\n",
        "In a sense, you can think of unsupervised learning as a means of discovering labels from the data itself.\n",
        "\n",
        "Unsupervised learning comprises tasks such as *dimensionality reduction*, *clustering*, and\n",
        "*anomaly detection*. Some unsupervised learning problems are:\n",
        "\n",
        "- Given detailed observations of distant galaxies, determine which features or combinations of\n",
        "  features best summarize the information.\n",
        "- Given a large collection of news articles, find recurring topics inside these articles.\n",
        "- Given a video, isolate a moving object and categorize in relation to other moving objects which have been seen.\n",
        "\n",
        "Sometimes the two types of learning may even be combined: e.g. unsupervised learning can be used to find useful\n",
        "features in heterogeneous data, and then these features can be used within a supervised\n",
        "framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saeOvmZaogob",
        "colab_type": "text"
      },
      "source": [
        "![alt text](https://miro.medium.com/max/2552/1*qYrLCg4h2NVXFNw424rKIQ.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pN_EHWzSrMyo",
        "colab_type": "text"
      },
      "source": [
        "### A Simple Example: The Iris Dataset\n",
        "As an example of a simple dataset, we're going to take a look at the iris dataset stored by scikit-learn.\n",
        "The data consists of measurements of three different iris flower species.  There are three different species of iris\n",
        "in this particular dataset: Iris-Setosa, Iris-Versicolor, and Iris-Virginica.\n",
        "\n",
        "The data consist of the following:\n",
        "\n",
        "- Features in the Iris dataset:\n",
        "\n",
        "  1. sepal length in cm\n",
        "  2. sepal width in cm\n",
        "  3. petal length in cm\n",
        "  4. petal width in cm\n",
        "\n",
        "- Target classes to predict:\n",
        "\n",
        "  1. Iris Setosa\n",
        "  2. Iris Versicolour\n",
        "  3. Iris Virginica\n",
        "  \n",
        "  ``scikit-learn`` embeds a copy of the iris CSV file along with a helper function to load it into numpy arrays:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1FjvG5_VIS3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 27\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Epv9bjXmrpfe",
        "colab_type": "text"
      },
      "source": [
        "The features of each sample flower are stored in the ``data`` attribute of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fl5MMZC4rogM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 28\n",
        "\n",
        "n_samples, n_features = iris.data.shape\n",
        "print('Number of samples:', n_samples)\n",
        "print('Number of features:', n_features)\n",
        "# the sepal length, sepal width, petal length and petal width of the first sample (first flower)\n",
        "print(iris.data[0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dsro0uaor7s2",
        "colab_type": "text"
      },
      "source": [
        "The information about the class of each sample is stored in the ``target`` attribute of the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UalkXh6yrus8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 29\n",
        "\n",
        "print('Target array shape:', iris.target.shape)\n",
        "print('\\nTarget array:', iris.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R9ob3AG_sdYB",
        "colab_type": "text"
      },
      "source": [
        "Using the NumPy's bincount function (above), we can see that the classes are distributed uniformly in this dataset - there are 50 flowers from each species, where\n",
        "\n",
        "- class 0: Iris-Setosa\n",
        "- class 1: Iris-Versicolor\n",
        "- class 2: Iris-Virginica\n",
        "\n",
        "These class names are stored in the last attribute, namely ``target_names``:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3gib94QLsG_7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 30\n",
        "\n",
        "print(iris.target_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IDEcPOxNsn0m",
        "colab_type": "text"
      },
      "source": [
        "This data is four dimensional, but we can visualize one or two of the dimensions\n",
        "at a time using a simple histogram.  Again, we'll start by enabling\n",
        "matplotlib inline mode:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AiltsHM5smyW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 31\n",
        "\n",
        "x_index = 3\n",
        "colors = ['red', 'blue', 'magenta']\n",
        "\n",
        "for label, color in zip(range(len(iris.target_names)), colors):\n",
        "    plt.hist(iris.data[iris.target==label, x_index], \n",
        "             label=iris.target_names[label],\n",
        "             color=color)\n",
        "\n",
        "plt.xlabel(iris.feature_names[x_index])\n",
        "plt.legend(loc='upper right')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMzachzJtAMs",
        "colab_type": "text"
      },
      "source": [
        "## Training and Testing Data\n",
        "\n",
        "To evaluate how well our supervised models generalize, we can split our data into a training and a test set. Below, we use 50% of the data for training, and 50% for testing. Other splits - such as 2/3 training and 1/3 test - could also be used. The most important thing is to fairly evaluate your system on data it *has not* seen during training!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w22I24HJs5Dq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 32\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X, y = iris.data, iris.target\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                                                    train_size=0.5,\n",
        "                                                    test_size=0.5,\n",
        "                                                    random_state=123)\n",
        "print(\"Labels for training and testing data\")\n",
        "print(train_y)\n",
        "print(test_y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeFA44M2uZl3",
        "colab_type": "text"
      },
      "source": [
        "**Tip: Stratified Split**\n",
        "\n",
        "Especially for relatively small datasets, it's better to stratify the split. Stratification means that we maintain the original class proportion of the dataset in the test and training sets. For example, after we randomly split the dataset as shown in the previous code example, we have the following class proportions in percent:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RLAyLl3FtQjS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 11\n",
        "\n",
        "train_X, test_X, train_y, test_y = train_test_split(X, y, \n",
        "                                                    train_size=0.5,\n",
        "                                                    test_size=0.5,\n",
        "                                                    random_state=123,\n",
        "                                                    stratify=y)\n",
        "\n",
        "print('All:', np.bincount(y) / float(len(y)) * 100.0)\n",
        "print('Training:', np.bincount(train_y) / float(len(train_y)) * 100.0)\n",
        "print('Test:', np.bincount(test_y) / float(len(test_y)) * 100.0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RxSGqlNBuhm4",
        "colab_type": "text"
      },
      "source": [
        "**Cross-validation**\n",
        "A common way to use more of the data to build a model, but also get a more robust estimate of the generalization performance, is cross-validation.\n",
        "In cross-validation, the data is split repeatedly into a training and non-overlapping test-sets, with a separate model built for every pair. The test-set scores are then aggregated for a more robust estimate.\n",
        "\n",
        "The most common way to do cross-validation is k-fold cross-validation, in which the data is first split into k (often 5 or 10) equal-sized folds, and then for each iteration, one of the k folds is used as test data, and the rest as training data:\n",
        "\n",
        "![alt text](https://media.springernature.com/lw785/springer-static/image/art%3A10.1007%2Fs10436-017-0301-4/MediaObjects/10436_2017_301_Fig1_HTML.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGxivJgHvZnm",
        "colab_type": "text"
      },
      "source": [
        "This way, each data point will be in the test-set exactly once, and we can use all but a k'th of the data for training. The ``sklearn.model_selection`` module has all functions related to cross validation. For example, we can use the Stratified K-Folds cross-validator:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sU7T0B6Uvg4y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 12\n",
        "\n",
        "from sklearn.model_selection import StratifiedKFold"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tDeaFcyviqY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 13\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5)\n",
        "for train, test in cv.split(iris.data, iris.target):\n",
        "    print(test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LN54ere4vxlW",
        "colab_type": "text"
      },
      "source": [
        "As you can see, there are some samples from the beginning, some from the middle, and some from the end, in each of the folds.\n",
        "This way, the class ratios are preserved. Let's visualize the split:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_NjOETxv2xT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## CODE CELL 14\n",
        "\n",
        "def plot_cv(cv, features, labels):\n",
        "    masks = []\n",
        "    for train, test in cv.split(features, labels):\n",
        "        mask = np.zeros(len(labels), dtype=bool)\n",
        "        mask[test] = 1\n",
        "        masks.append(mask)\n",
        "    \n",
        "    plt.matshow(masks, cmap='gray_r')\n",
        "    \n",
        "plot_cv(StratifiedKFold(n_splits=5), iris.data, iris.target)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zvq893QDwwDN",
        "colab_type": "text"
      },
      "source": [
        "## Supervised Learning: Classification Examples\n",
        "To visualize the workings of machine learning algorithms, it is often helpful to study two-dimensional or one-dimensional data, that is, data with only one or two features. While in practice, datasets usually have many more features, it is hard to plot high-dimensional data on two-dimensional screens.\n",
        "\n",
        "We will illustrate some very simple examples before we move on to more \"real world\" data sets.\n",
        "\n",
        "First, we will look at a two class classification problems in two dimensions. We use the synthetic data generated by the ``make_blobs`` function, which generates clusters of points.\n",
        "\n",
        "\n",
        "## We will covere these topics in more details in next workshop\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siILhfroIS3x",
        "colab_type": "text"
      },
      "source": [
        "*References*:\n",
        "\n",
        "The following materials were consulted during development of this notebook:\n",
        "\n",
        "N.P. Rougier, *Matplotlib Tutorial*. https://www.labri.fr/perso/nrougier/teaching/matplotlib/.\n",
        "\n",
        "The Matplotlib Development Team, *Pyplot Tutorial*. https://matplotlib.org/tutorials/introductory/pyplot.html.\n",
        "\n",
        "J. VanderPlas, \"Chapter 4 - Visualization with Matplotlib,\" *Python Data Science Handbook: Essential Tools for Working with Data*. O'Reilly Media, 2016. [Online] https://jakevdp.github.io/PythonDataScienceHandbook/index.html.\n",
        "\n",
        "M. Waskom, *Seaborn Tutorial*. https://seaborn.pydata.org/tutorial.html#tutorial.\n"
      ]
    }
  ]
}